{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Tratamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "\n",
    "from warnings import simplefilter \n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.set_option('display.max_columns', 999)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin = pd.read_csv('data/dados_cluster_FIN.csv.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_NASCIMENTO 13\n",
      "SEGMENTO 6284\n"
     ]
    }
   ],
   "source": [
    "for col in fin.columns:\n",
    "    a = fin[col].isna().sum()\n",
    "    if a > 0:\n",
    "        print(col, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEGMENTO 6276\n"
     ]
    }
   ],
   "source": [
    "# Remover 13 linhas com DATA_NASCIMENTO faltante\n",
    "\n",
    "df_clean = fin.dropna(subset=['DATA_NASCIMENTO'], inplace=False)\n",
    "\n",
    "for col in df_clean.columns:\n",
    "    a = df_clean[col].isna().sum()\n",
    "    if a > 0:\n",
    "        print(col, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar Features\n",
    "\n",
    "df_clean[xxxxxxxxxxxxxx] = round(df_clean['xxxxxxxxxxxxxx'] / df_clean['xxxxxxxxxxxxxx'], 3)\n",
    "df_clean['xxxxxxxxxxxxxx'] = round((df_clean['xxxxxxxxxxxxxx'] + df_clean['xxxxxxxxxxxxxx']) / df_clean['xxxxxxxxxxxxxx'], 3)\n",
    "df_clean['xxxxxxxxxxxxxx'] = round(df_clean['xxxxxxxxxxxxxx'] / df_clean['xxxxxxxxxxxxxx'], 3)\n",
    "df_clean['xxxxxxxxxxxxxx'] = round(df_clean['xxxxxxxxxxxxxx'] + df_clean['xxxxxxxxxxxxxx'], 2)\n",
    "df_clean['xxxxxxxxxxxxxx'] = round(df_clean['xxxxxxxxxxxxxx'] / df_clean['xxxxxxxxxxxxxx'], 3)\n",
    "df_clean['xxxxxxxxxxxxxx'] = np.where(df_clean['xxxxxxxxxxxxxx'] >= 1,'SIM','NAO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colunas para excluir\n",
    "\n",
    "col2drop = [\n",
    "    xxxxxxxxxxxxxxxxxx\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tamanho inicial:  (248186, 166)\n",
      "tamanho após remoção de colunas:  (248186, 101)\n"
     ]
    }
   ],
   "source": [
    "print('tamanho inicial: ', df_clean.shape)\n",
    "df_clean = df_clean.drop(columns=col2drop, axis=1)\n",
    "print('tamanho após remoção de colunas: ', df_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERC_PAG_EM_DIA 16663\n"
     ]
    }
   ],
   "source": [
    "# Check NaN\n",
    "for col in df_clean.columns:\n",
    "    a = df_clean[col].isna().sum()\n",
    "    if a > 0:\n",
    "        print(col, a)\n",
    "\n",
    "# Fill NaN\n",
    "df_clean.fillna(value=0, inplace=True)\n",
    "\n",
    "for col in df_clean.columns:\n",
    "    a = df_clean[col].isna().sum()\n",
    "    if a > 0:\n",
    "        print(col, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removeu os nulos\n",
    "for col in df_clean.columns:\n",
    "    a = df_clean[col].isna().sum()\n",
    "    if a > 0:\n",
    "        print(col, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding: \n",
    "\n",
    "cols_enc = ['xxxxxxxxxxxxxx', 'xxxxxxxxxxxxxx', 'xxxxxxxxxxxxxx', 'xxxxxxxxxxxxxx', 'xxxxxxxxxxxxxx', 'xxxxxxxxxxxxxx']\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "df_norm = pd.DataFrame()\n",
    "enc_mapping = list()\n",
    "\n",
    "for col in cols_enc:\n",
    "    encoded = encoder.fit_transform(df_clean[col].astype(str))\n",
    "    df_norm[col] = encoded\n",
    "    mapping = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\n",
    "    enc_mapping.append([col, mapping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14481/3964076308.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_norm[coluna] = encoded\n"
     ]
    }
   ],
   "source": [
    "# Normalizar: \n",
    "\n",
    "cols_norm = [x for x in df_clean.select_dtypes(include=['int64', 'float64']).columns]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "for coluna in cols_norm:\n",
    "    encoded = scaler.fit_transform(df_clean[coluna].values.reshape(-1, 1))\n",
    "    df_norm[coluna] = encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check df normalizado\n",
    "for col in df_norm.columns:\n",
    "    a = df_norm[col].isna().sum()\n",
    "    if a > 0:\n",
    "        print(col, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvando arquivos\n",
    "\n",
    "df_clean.to_csv('./data/data_fin_clean.csv', index=False)\n",
    "df_norm.to_csv('./data/data_fin_norm.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "falconi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1742243f245c369aba97dfcdbb850561fcc24820d8c67b03f82852a8dc427f00"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
